// Copyright 2017 Google Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include "sling/myelin/generator/expression.h"

#define __ masm->

namespace sling {
namespace myelin {

using namespace jit;

// Generate vector float expression using AVX and YMM registers.
class VectorFltAVX256Generator : public ExpressionGenerator {
 public:
  VectorFltAVX256Generator() {
    model_.mov_reg_reg = true;
    model_.mov_reg_imm = true;
    model_.mov_reg_mem = true;
    model_.mov_mem_reg = true;
    model_.op_reg_reg_reg = true;
    model_.op_reg_reg_imm = true;
    model_.op_reg_reg_mem = true;
    model_.func_reg_reg = true;
    model_.func_reg_imm = true;
    model_.func_reg_mem = true;
    if (CPU::Enabled(FMA3)) {
      model_.fm_reg_reg_reg = true;
      model_.fm_reg_reg_imm = true;
      model_.fm_reg_reg_mem = true;
    }
    model_.cond_reg_reg_reg = true;
    model_.cond_reg_mem_reg = true;
  }

  string Name() override { return "VFltAVX256"; }

  int VectorSize() override { return YMMRegSize; }

  void Reserve() override {
    // Reserve YMM registers.
    index_->ReserveYMMRegisters(instructions_.NumRegs());

    // Allocate auxiliary registers.
    int num_mm_aux = 0;
    if (!CPU::Enabled(AVX2)) {
      if (instructions_.Has(Express::CVTEXPINT) ||
          instructions_.Has(Express::CVTINTEXP)) {
        num_mm_aux = std::max(num_mm_aux, 1);
      }
      if (instructions_.Has(Express::SUBINT)) {
        num_mm_aux = std::max(num_mm_aux, 3);
      }
    }
    if (instructions_.Has(Express::SUM) ||
        instructions_.Has(Express::PRODUCT) ||
        instructions_.Has(Express::MIN) ||
        instructions_.Has(Express::MAX)) {
      num_mm_aux = std::max(num_mm_aux, 1);
    }
    if (instructions_.Has(Express::CVTINTFLT) && type_ == DT_DOUBLE) {
      num_mm_aux = std::max(num_mm_aux, 1);
    }
    index_->ReserveAuxYMMRegisters(num_mm_aux);
  }

  void Generate(Express::Op *instr, MacroAssembler *masm) override {
    switch (instr->type) {
      case Express::MOV:
        if (IsLoadZero(instr) && masm->Enabled(ZEROIDIOM)) {
          // Use XOR to zero register instead of loading constant from memory.
          // This uses the floating point version of xor to avoid bypass delays
          // between integer and floating point units.
          switch (type_) {
            case DT_FLOAT:
              __ vxorps(ymm(instr->dst), ymm(instr->dst), ymm(instr->dst));
              break;
            case DT_DOUBLE:
              __ vxorpd(ymm(instr->dst), ymm(instr->dst), ymm(instr->dst));
              break;
            default: UNSUPPORTED;
          }
        } else {
          GenerateYMMVectorMove(instr, masm);
        }
        break;
      case Express::ADD:
        GenerateYMMFltOp(instr,
            &Assembler::vaddps, &Assembler::vaddpd,
            &Assembler::vaddps, &Assembler::vaddpd,
            masm);
        break;
      case Express::SUB:
        GenerateYMMFltOp(instr,
            &Assembler::vsubps, &Assembler::vsubpd,
            &Assembler::vsubps, &Assembler::vsubpd,
            masm);
        break;
      case Express::MUL:
        GenerateYMMFltOp(instr,
            &Assembler::vmulps, &Assembler::vmulpd,
            &Assembler::vmulps, &Assembler::vmulpd,
            masm);
        break;
      case Express::DIV:
        GenerateYMMFltOp(instr,
            &Assembler::vdivps, &Assembler::vdivpd,
            &Assembler::vdivps, &Assembler::vdivpd,
            masm);
        break;
      case Express::MINIMUM:
        GenerateYMMFltOp(instr,
            &Assembler::vminps, &Assembler::vminpd,
            &Assembler::vminps, &Assembler::vminpd,
            masm);
        break;
      case Express::MAXIMUM:
        GenerateYMMFltOp(instr,
            &Assembler::vmaxps, &Assembler::vmaxpd,
            &Assembler::vmaxps, &Assembler::vmaxpd,
            masm);
        break;
      case Express::SQRT:
        GenerateYMMFltOp(instr,
            &Assembler::vsqrtps, &Assembler::vsqrtpd,
            &Assembler::vsqrtps, &Assembler::vsqrtpd,
            masm);
        break;
      case Express::MULADD132:
        GenerateYMMFltOp(instr,
            &Assembler::vfmadd132ps, &Assembler::vfmadd132pd,
            &Assembler::vfmadd132ps, &Assembler::vfmadd132pd,
            masm, 2);
        break;
      case Express::MULADD213:
        GenerateYMMFltOp(instr,
            &Assembler::vfmadd213ps, &Assembler::vfmadd213pd,
            &Assembler::vfmadd213ps, &Assembler::vfmadd213pd,
            masm, 2);
        break;
      case Express::MULADD231:
        GenerateYMMFltOp(instr,
            &Assembler::vfmadd231ps, &Assembler::vfmadd231pd,
            &Assembler::vfmadd231ps, &Assembler::vfmadd231pd,
            masm, 2);
        break;
      case Express::MULSUB132:
        GenerateYMMFltOp(instr,
            &Assembler::vfmsub132ps, &Assembler::vfmsub132pd,
            &Assembler::vfmsub132ps, &Assembler::vfmsub132pd,
            masm, 2);
        break;
      case Express::MULSUB213:
        GenerateYMMFltOp(instr,
            &Assembler::vfmsub213ps, &Assembler::vfmsub213pd,
            &Assembler::vfmsub213ps, &Assembler::vfmsub213pd,
            masm, 2);
        break;
      case Express::MULSUB231:
        GenerateYMMFltOp(instr,
            &Assembler::vfmsub231ps, &Assembler::vfmsub231pd,
            &Assembler::vfmsub231ps, &Assembler::vfmsub231pd,
            masm, 2);
        break;
      case Express::CMPEQOQ:
        GenerateCompare(instr, masm, CMP_EQ_OQ);
        break;
      case Express::CMPNEUQ:
        GenerateCompare(instr, masm, CMP_NEQ_UQ);
        break;
      case Express::CMPLTOQ:
        GenerateCompare(instr, masm, CMP_LT_OQ);
        break;
      case Express::CMPLEOQ:
        GenerateCompare(instr, masm, CMP_LE_OQ);
        break;
      case Express::CMPGTOQ:
        GenerateCompare(instr, masm, CMP_GT_OQ);
        break;
      case Express::CMPGEOQ:
        GenerateCompare(instr, masm, CMP_GE_OQ);
        break;
      case Express::COND:
        GenerateConditional(instr, masm);
        break;
      case Express::SELECT:
        GenerateSelect(instr, masm);
        break;
      case Express::BITAND:
      case Express::AND:
        GenerateYMMFltOp(instr,
            &Assembler::vandps, &Assembler::vandpd,
            &Assembler::vandps, &Assembler::vandpd,
            masm);
        break;
      case Express::BITOR:
      case Express::OR:
        GenerateYMMFltOp(instr,
            &Assembler::vorps, &Assembler::vorpd,
            &Assembler::vorps, &Assembler::vorpd,
            masm);
        break;
      case Express::XOR:
        GenerateYMMFltOp(instr,
            &Assembler::vxorps, &Assembler::vxorpd,
            &Assembler::vxorps, &Assembler::vxorpd,
            masm);
        break;
      case Express::ANDNOT:
        GenerateYMMFltOp(instr,
            &Assembler::vandnps, &Assembler::vandnpd,
            &Assembler::vandnps, &Assembler::vandnpd,
            masm);
        break;
      case Express::NOT:
        GenerateNot(instr, masm);
        break;
      case Express::FLOOR:
        GenerateYMMFltOp(instr,
            &Assembler::vroundps, &Assembler::vroundpd,
            &Assembler::vroundps, &Assembler::vroundpd,
            round_down, masm);
        break;
      case Express::CVTFLTINT:
        GenerateFltToInt(instr, masm);
        break;
      case Express::CVTINTFLT:
        GenerateIntToFlt(instr, masm);
        break;
      case Express::CVTEXPINT:
        GenerateShift(instr, masm, false, type_ == DT_FLOAT ? 23 : 52);
        break;
      case Express::CVTINTEXP:
        GenerateShift(instr, masm, true, type_ == DT_FLOAT ? 23 : 52);
        break;
      case Express::SUBINT:
        GenerateIntegerSubtract(instr, masm);
        break;
      case Express::SUM:
        GenerateYMMFltAccOp(instr,
            &Assembler::vaddps, &Assembler::vaddpd,
            &Assembler::vaddps, &Assembler::vaddpd,
            masm);
        break;
      case Express::PRODUCT:
        GenerateYMMFltAccOp(instr,
            &Assembler::vmulps, &Assembler::vmulpd,
            &Assembler::vmulps, &Assembler::vmulpd,
            masm);
        break;
      case Express::MIN:
        GenerateYMMFltAccOp(instr,
            &Assembler::vminps, &Assembler::vminpd,
            &Assembler::vminps, &Assembler::vminpd,
            masm);
        break;
      case Express::MAX:
        GenerateYMMFltAccOp(instr,
            &Assembler::vmaxps, &Assembler::vmaxpd,
            &Assembler::vmaxps, &Assembler::vmaxpd,
            masm);
        break;
      default:
        UNSUPPORTED;
    }
  }

  // Generate float to integer conversion.
  void GenerateFltToInt(Express::Op *instr, MacroAssembler *masm) {
    // Convert eight floats or four doubles to int32.
    GenerateYMMFltOp(instr,
        &Assembler::vcvttps2dq, &Assembler::vcvttpd2dq,
        &Assembler::vcvttps2dq, &Assembler::vcvttpd2dq,
        masm);

    // Convert int32 to int64 for doubles.
    if (type_ == DT_DOUBLE) {
      __ vpmovsxdq(ymm(instr->dst), xmm(instr->dst));
    }
  }

  // Generate integer to float conversion.
  void GenerateIntToFlt(Express::Op *instr, MacroAssembler *masm) {
    if (type_ == DT_FLOAT) {
      // Convert four int32s to floats.
      if (instr->src != -1) {
        __ vcvtdq2ps(ymm(instr->dst), ymm(instr->src));
      } else {
        __ vcvtdq2ps(ymm(instr->dst), addr(instr->args[0]));
      }
    } else if (type_ == DT_DOUBLE) {
      // Make sure source is in a register.
      int src = instr->src;
      if (instr->src == -1) {
        GenerateYMMMoveMemToReg(ymm(instr->dst), addr(instr->args[0]), masm);
        src = instr->dst;
      }

      // Convert four int64s to four int32s in lower lane.
      __ vperm2f128(ymmaux(0), ymm(src), ymm(src), 1);
      __ vpermilps(ymm(src), ymm(src), 0xD8);
      __ vpermilps(ymmaux(0), ymmaux(0), 0x8D);
      __ vblendps(ymm(src), ymm(src), ymmaux(0), 0x3C);

      // Convert four int32s in lower lane to doubles.
      __ vcvtdq2pd(ymm(instr->dst), ymm(src));
    } else {
      UNSUPPORTED;
    }
  }

  // Generate left/right shift.
  void GenerateShift(Express::Op *instr, MacroAssembler *masm,
                     bool left, int bits) {
    // Make sure source is in a register.
    CHECK(instr->dst != -1);
    int src = instr->src;
    if (instr->src == -1) {
      GenerateYMMMoveMemToReg(ymm(instr->dst), addr(instr->args[0]), masm);
      src = instr->dst;
    }

    switch (type_) {
      case DT_FLOAT:
        if (CPU::Enabled(AVX2)) {
          // Shift ymm register.
          if (left) {
            __ vpslld(ymm(instr->dst), ymm(src), bits);
          } else {
            __ vpsrld(ymm(instr->dst), ymm(src), bits);
          }
        } else {
          // Shift ymm register by shifting lo and hi xmm registers.
          __ vextractf128(xmmaux(0), ymm(src), 1);
          if (left) {
            __ vpslld(xmmaux(0), xmmaux(0), bits);
            __ vpslld(xmm(instr->dst), xmm(src), bits);
          } else {
            __ vpsrld(xmmaux(0), xmmaux(0), bits);
            __ vpsrld(xmm(instr->dst), xmm(src), bits);
          }
          __ vinsertf128(ymm(instr->dst), ymm(instr->dst), xmmaux(0), 1);
        }
        break;
      case DT_DOUBLE:
        if (CPU::Enabled(AVX2)) {
          // Shift ymm register.
          if (left) {
            __ vpsllq(ymm(instr->dst), ymm(src), bits);
          } else {
            __ vpsrlq(ymm(instr->dst), ymm(src), bits);
          }
        } else {
          // Shift ymm register by shifting lo and hi xmm registers.
          __ vextractf128(xmmaux(0), ymm(src), 1);
          if (left) {
            __ vpsllq(xmmaux(0), xmmaux(0), bits);
            __ vpsllq(xmm(instr->dst), xmm(src), bits);
          } else {
            __ vpsrlq(xmmaux(0), xmmaux(0), bits);
            __ vpsrlq(xmm(instr->dst), xmm(src), bits);
          }
          __ vinsertf128(ymm(instr->dst), ymm(instr->dst), xmmaux(0), 1);
        }
        break;
      default: UNSUPPORTED;
    }
  }

  // Generate integer subtract.
  void GenerateIntegerSubtract(Express::Op *instr, MacroAssembler *masm) {
    if (CPU::Enabled(AVX2)) {
      GenerateYMMFltOp(instr,
          &Assembler::vpsubd, &Assembler::vpsubq,
          &Assembler::vpsubd, &Assembler::vpsubq,
          masm);
    } else {
      // Move second operand to register.
      CHECK(instr->dst != -1);
      YMMRegister src2;
      if (instr->src2 != -1) {
        src2 = ymm(instr->src2);
      } else {
        GenerateYMMMoveMemToReg(ymmaux(0), addr(instr->args[1]), masm);
        src2 = ymmaux(0);
      }

      // Subtract upper and lower parts separately.
      __ vextractf128(xmmaux(1), ymm(instr->src), 1);
      __ vextractf128(xmmaux(2), src2, 1);
      switch (type_) {
        case DT_FLOAT:
          __ vpsubd(xmmaux(1), xmmaux(1), xmmaux(2));
          __ vpsubd(xmm(instr->dst), xmm(instr->src), src2.xmm());
          break;
        case DT_DOUBLE:
          __ vpsubq(xmmaux(1), xmmaux(1), xmmaux(2));
          __ vpsubq(xmm(instr->dst), xmm(instr->src), src2.xmm());
          break;
        default: UNSUPPORTED;
      }
      __ vinsertf128(ymm(instr->dst), ymm(instr->dst), xmmaux(1), 1);
    }
  }

  // Generate logical not.
  void GenerateNot(Express::Op *instr, MacroAssembler *masm) {
    // Compute not(x) = xor(1,x).
    __ vpcmpeqd(ymm(instr->dst), ymm(instr->dst), ymm(instr->dst));
    if (instr->src != -1) {
      // NOT dst,reg
      switch (type_) {
        case DT_FLOAT:
          __ vxorps(ymm(instr->dst), ymm(instr->dst), ymm(instr->src));
          break;
        case DT_DOUBLE:
          __ vxorpd(ymm(instr->dst), ymm(instr->dst), ymm(instr->src));
          break;
        default: UNSUPPORTED;
      }
    } else {
      // NOT dst,[mem]
      switch (type_) {
        case DT_FLOAT:
          __ vxorps(ymm(instr->dst), ymm(instr->dst), addr(instr->args[0]));
          break;
        case DT_DOUBLE:
          __ vxorpd(ymm(instr->dst), ymm(instr->dst), addr(instr->args[0]));
          break;
        default: UNSUPPORTED;
      }
    }
  }

  // Generate compare.
  void GenerateCompare(Express::Op *instr, MacroAssembler *masm, int8 code) {
    GenerateYMMFltOp(instr,
        &Assembler::vcmpps, &Assembler::vcmppd,
        &Assembler::vcmpps, &Assembler::vcmppd,
        code, masm);
  }

  // Generate conditional.
  void GenerateConditional(Express::Op *instr, MacroAssembler *masm) {
    CHECK(instr->dst != -1);
    CHECK(instr->src2 != -1);
    CHECK(instr->mask != -1);
    if (instr->src != -1) {
      // COND dst[mask],src,src2
      switch (type_) {
        case DT_FLOAT:
          __ vblendvps(ymm(instr->dst), ymm(instr->src2), ymm(instr->src),
                       ymm(instr->mask));
          break;
        case DT_DOUBLE:
          __ vblendvpd(ymm(instr->dst), ymm(instr->src2), ymm(instr->src),
                       ymm(instr->mask));
          break;
        default: UNSUPPORTED;
      }
    } else {
      // COND dst[mask],[mem],src2
      switch (type_) {
        case DT_FLOAT:
          __ vblendvps(ymm(instr->dst), ymm(instr->src2), addr(instr->args[1]),
                       ymm(instr->mask));
          break;
        case DT_DOUBLE:
          __ vblendvpd(ymm(instr->dst), ymm(instr->src2), addr(instr->args[1]),
                       ymm(instr->mask));
          break;
        default: UNSUPPORTED;
      }
    }
  }

  // Generate masked select.
  void GenerateSelect(Express::Op *instr, MacroAssembler *masm) {
    CHECK(instr->dst != -1);
    CHECK(instr->mask != -1);
    if (instr->src != -1) {
      // SELECT dst[mask],src
      switch (type_) {
        case DT_FLOAT:
          __ vandps(ymm(instr->dst), ymm(instr->mask), ymm(instr->src));
          break;
        case DT_DOUBLE:
          __ vandpd(ymm(instr->dst), ymm(instr->mask), ymm(instr->src));
          break;
        default: UNSUPPORTED;
      }
    } else {
      // SELECT dst[mask],[mem]
      switch (type_) {
        case DT_FLOAT:
          __ vandps(ymm(instr->dst), ymm(instr->mask), addr(instr->args[1]));
          break;
        case DT_DOUBLE:
          __ vandpd(ymm(instr->dst), ymm(instr->mask), addr(instr->args[1]));
          break;
        default: UNSUPPORTED;
      }
    }
  }

  // Generate code for reduction operation.
  void GenerateReduce(Express::Op *instr, MacroAssembler *masm) override {
    auto acc = ymm(instr->acc);
    auto aux = ymmaux(0);
    __ Reduce(ReduceOp(instr), type_, acc, aux);

    switch (type_) {
      case DT_FLOAT:
        if (instr->dst != -1) {
          __ vmovss(xmm(instr->dst), xmm(instr->dst), xmm(instr->acc));
        } else {
          __ vmovss(addr(instr->result), xmm(instr->acc));
        }
        break;
      case DT_DOUBLE:
        if (instr->dst != -1) {
          __ vmovsd(xmm(instr->dst), xmm(instr->dst), xmm(instr->acc));
        } else {
          __ vmovsd(addr(instr->result), xmm(instr->acc));
        }
        break;
      default: UNSUPPORTED;
    }
  }
};

ExpressionGenerator *CreateVectorFltAVX256Generator() {
  return new VectorFltAVX256Generator();
}

}  // namespace myelin
}  // namespace sling

